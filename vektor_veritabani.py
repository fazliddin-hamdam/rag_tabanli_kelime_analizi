# vektor_veritabani.py - Optimized Batch Processing

import os
import numpy as np
import chromadb

print("ğŸš€ Kelime VektÃ¶rleri ChromaDB'ye YÃ¼kleniyor...")

# 1) KalÄ±cÄ± DB yolunu ayarla
BASE_DIR = os.path.dirname(__file__)
DB_DIR = os.path.join(BASE_DIR, "db")
os.makedirs(DB_DIR, exist_ok=True)

# 2) PersistentClient ile baÄŸlantÄ±
try:
    client = chromadb.PersistentClient(path=DB_DIR)
    print("âœ… ChromaDB baÄŸlantÄ±sÄ± kuruldu")
except Exception as e:
    print(f"âŒ ChromaDB baÄŸlantÄ± hatasÄ±: {e}")
    exit(1)

# 3) Koleksiyonu oluÅŸtur/al (cosine distance ile)
try:
    collection = client.get_or_create_collection(
        name="kelime_vektorleri",
        metadata={"hnsw:space": "cosine"}
    )
    print("âœ… Kelime vektÃ¶rleri koleksiyonu hazÄ±r")
except Exception as e:
    print(f"âŒ Koleksiyon oluÅŸturma hatasÄ±: {e}")
    exit(1)

# 4) DosyalarÄ± kontrol et
if not os.path.exists("kelimeler.txt"):
    print("âŒ kelimeler.txt dosyasÄ± bulunamadÄ±!")
    exit(1)

if not os.path.exists("kelime_vektorleri.npy"):
    print("âŒ kelime_vektorleri.npy dosyasÄ± bulunamadÄ±!")
    exit(1)

# 5) Kelimeleri ve vektÃ¶rleri yÃ¼kle
print("ğŸ“š Kelimeler yÃ¼kleniyor...")
kelimeler = [l.strip() for l in open("kelimeler.txt", encoding="utf-8") if l.strip()]

print("ğŸ”¢ Kelime vektÃ¶rleri yÃ¼kleniyor...")
kelime_vektorleri = np.load("kelime_vektorleri.npy")

print(f"ğŸ“Š Toplam kelime sayÄ±sÄ±: {len(kelimeler)}")
print(f"ğŸ§® VektÃ¶r boyutu: {kelime_vektorleri.shape}")

# 6) Varolan kayÄ±tlarÄ± temizle (isteÄŸe baÄŸlÄ±)
try:
    existing_count = collection.count()
    if existing_count > 0:
        print(f"ğŸ—‘ï¸  Mevcut {existing_count} kayÄ±t temizleniyor...")
        # TÃ¼m kayÄ±tlarÄ± sil
        all_ids = [str(i) for i in range(existing_count)]
        collection.delete(ids=all_ids)
except Exception as e:
    print(f"âš ï¸  Temizleme sÄ±rasÄ±nda hata (normal olabilir): {e}")

# 7) âš¡ BATCH PROCESSING - Ã‡ok daha hÄ±zlÄ±!
print("ğŸ’¾ Kelimeler toplu olarak ChromaDB'ye ekleniyor...")
try:
    # BÃ¼yÃ¼k koleksiyonlar iÃ§in batch boyutu
    batch_size = 1000  # Kelimeler iÃ§in daha bÃ¼yÃ¼k batch boyutu kullanabiliriz
    
    for i in range(0, len(kelimeler), batch_size):
        end_idx = min(i + batch_size, len(kelimeler))
        
        # Batch verileri hazÄ±rla
        batch_kelimeler = kelimeler[i:end_idx]
        batch_vektorler = kelime_vektorleri[i:end_idx]
        batch_ids = [str(j) for j in range(i, end_idx)]
        
        # VektÃ¶rleri liste formatÄ±na Ã§evir
        batch_embeddings = [vec.tolist() for vec in batch_vektorler]
        
        # Toplu ekleme - tek seferde 1000 kelime!
        collection.add(
            embeddings=batch_embeddings,
            documents=batch_kelimeler,
            ids=batch_ids
        )
        
        print(f"  ğŸ“¦ {end_idx}/{len(kelimeler)} kelime iÅŸlendi...")

    print(f"âœ… {len(kelimeler)} kelime baÅŸarÄ±yla ChromaDB'ye yÃ¼klendi!")
    print(f"ğŸ Toplam kayÄ±t sayÄ±sÄ±: {collection.count()}")
    
except Exception as e:
    print(f"âŒ Ekleme sÄ±rasÄ±nda hata: {e}")
    exit(1)

print("ğŸ¯ Ä°ÅŸlem tamamlandÄ±!")
print("ğŸ’¡ ArtÄ±k app.py'yi Ã§alÄ±ÅŸtÄ±rarak arama yapabilirsiniz!")
