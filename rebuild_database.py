#!/usr/bin/env python3
"""
ğŸš€ ChromaDB Database Rebuild - Optimized Batch Processing
TÃ¼m veritabanÄ± koleksiyonlarÄ±nÄ± optimized batch processing ile yeniden oluÅŸturur.
"""

import os
import sys
import time
import shutil
import numpy as np
import chromadb
from pathlib import Path

def clear_database():
    """Mevcut veritabanÄ±nÄ± temizle"""
    db_dir = "db"
    if os.path.exists(db_dir):
        print(f"ğŸ—‘ï¸  Mevcut veritabanÄ± temizleniyor: {db_dir}")
        shutil.rmtree(db_dir)
    os.makedirs(db_dir, exist_ok=True)
    print("âœ… Temiz veritabanÄ± dizini oluÅŸturuldu")

def check_files():
    """Gerekli dosyalarÄ± kontrol et"""
    required_files = [
        "kelimeler.txt",
        "kelime_vektorleri.npy",
        "metinler.txt", 
        "metin_vektorleri.npy",
        "iliskiler.txt"
    ]
    
    missing_files = []
    for file in required_files:
        if not os.path.exists(file):
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ Eksik dosyalar: {', '.join(missing_files)}")
        return False
    
    print("âœ… TÃ¼m gerekli dosyalar mevcut")
    return True

def rebuild_word_vectors():
    """Kelime vektÃ¶rlerini batch processing ile yeniden oluÅŸtur"""
    print("\nğŸ“š KELIME VEKTÃ–RLERÄ° YENÄ°DEN OLUÅTURULUYOR")
    print("=" * 50)
    
    start_time = time.time()
    
    # ChromaDB baÄŸlantÄ±sÄ±
    client = chromadb.PersistentClient(path="db")
    
    # Koleksiyon oluÅŸtur
    collection = client.get_or_create_collection(
        name="kelime_vektorleri",
        metadata={"hnsw:space": "cosine"}
    )
    
    # Verileri yÃ¼kle
    print("ğŸ“– Kelimeler yÃ¼kleniyor...")
    with open("kelimeler.txt", "r", encoding="utf-8") as f:
        kelimeler = [line.strip() for line in f if line.strip()]
    
    print("ğŸ”¢ Kelime vektÃ¶rleri yÃ¼kleniyor...")
    kelime_vektorleri = np.load("kelime_vektorleri.npy")
    
    print(f"ğŸ“Š Toplam kelime sayÄ±sÄ±: {len(kelimeler)}")
    
    # Batch processing
    batch_size = 1000
    print(f"ğŸ’¾ Batch processing baÅŸlÄ±yor (batch_size={batch_size})...")
    
    for i in range(0, len(kelimeler), batch_size):
        end_idx = min(i + batch_size, len(kelimeler))
        
        batch_kelimeler = kelimeler[i:end_idx]
        batch_vektorler = kelime_vektorleri[i:end_idx]
        batch_ids = [str(j) for j in range(i, end_idx)]
        batch_embeddings = [vec.tolist() for vec in batch_vektorler]
        
        collection.add(
            embeddings=batch_embeddings,
            documents=batch_kelimeler,
            ids=batch_ids
        )
        
        print(f"  ğŸ“¦ {end_idx}/{len(kelimeler)} kelime iÅŸlendi...")
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"âœ… Kelime vektÃ¶rleri tamamlandÄ±: {duration:.2f} saniye")
    print(f"ğŸ Toplam kayÄ±t sayÄ±sÄ±: {collection.count()}")
    
    return duration

def rebuild_sentence_vectors():
    """CÃ¼mle vektÃ¶rlerini batch processing ile yeniden oluÅŸtur"""
    print("\nğŸ“ CÃœMLE VEKTÃ–RLERÄ° YENÄ°DEN OLUÅTURULUYOR")
    print("=" * 50)
    
    start_time = time.time()
    
    # ChromaDB baÄŸlantÄ±sÄ±
    client = chromadb.PersistentClient(path="db")
    
    # Koleksiyon oluÅŸtur
    collection = client.get_or_create_collection(
        name="metin_vektorleri",
        metadata={"hnsw:space": "cosine"}
    )
    
    # Verileri yÃ¼kle
    print("ğŸ“– CÃ¼mleler yÃ¼kleniyor...")
    with open("metinler.txt", "r", encoding="utf-8") as f:
        metinler = [line.strip() for line in f if line.strip()]
    
    print("ğŸ”¢ CÃ¼mle vektÃ¶rleri yÃ¼kleniyor...")
    metin_vektorleri = np.load("metin_vektorleri.npy")
    
    print(f"ğŸ“Š Toplam cÃ¼mle sayÄ±sÄ±: {len(metinler)}")
    
    # Batch processing
    batch_size = 500
    print(f"ğŸ’¾ Batch processing baÅŸlÄ±yor (batch_size={batch_size})...")
    
    for i in range(0, len(metinler), batch_size):
        end_idx = min(i + batch_size, len(metinler))
        
        batch_metinler = metinler[i:end_idx]
        batch_vektorler = metin_vektorleri[i:end_idx]
        batch_ids = [str(j) for j in range(i, end_idx)]
        batch_embeddings = [vec.tolist() for vec in batch_vektorler]
        
        collection.add(
            embeddings=batch_embeddings,
            documents=batch_metinler,
            ids=batch_ids
        )
        
        print(f"  ğŸ“¦ {end_idx}/{len(metinler)} cÃ¼mle iÅŸlendi...")
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"âœ… CÃ¼mle vektÃ¶rleri tamamlandÄ±: {duration:.2f} saniye")
    print(f"ğŸ Toplam kayÄ±t sayÄ±sÄ±: {collection.count()}")
    
    return duration

def verify_database():
    """VeritabanÄ±nÄ± doÄŸrula"""
    print("\nğŸ” VERÄ°TABANI DOÄRULAMA")
    print("=" * 30)
    
    client = chromadb.PersistentClient(path="db")
    
    # KoleksiyonlarÄ± kontrol et
    collections = client.list_collections()
    print(f"ğŸ“‹ Bulunan koleksiyonlar: {len(collections)}")
    
    for collection_info in collections:
        collection = client.get_collection(collection_info.name)
        count = collection.count()
        print(f"  â€¢ {collection_info.name}: {count} kayÄ±t")
    
    # Test aramasÄ± yap
    try:
        word_collection = client.get_collection("kelime_vektorleri")
        results = word_collection.query(
            query_texts=["test"],
            n_results=3
        )
        print(f"âœ… Kelime aramasÄ± test edildi: {len(results['documents'][0])} sonuÃ§")
        
        sentence_collection = client.get_collection("metin_vektorleri")
        results = sentence_collection.query(
            query_texts=["test cÃ¼mlesi"],
            n_results=3
        )
        print(f"âœ… CÃ¼mle aramasÄ± test edildi: {len(results['documents'][0])} sonuÃ§")
        
    except Exception as e:
        print(f"âŒ Test aramasÄ± baÅŸarÄ±sÄ±z: {e}")
        return False
    
    return True

def main():
    print("ğŸ¯ ChromaDB Database Rebuild - Optimized Batch Processing")
    print("=" * 60)
    
    total_start_time = time.time()
    
    # DosyalarÄ± kontrol et
    if not check_files():
        print("âŒ Gerekli dosyalar eksik. Ä°ÅŸlem sonlandÄ±rÄ±lÄ±yor.")
        sys.exit(1)
    
    # Onay al
    response = input("\nâš ï¸  Bu iÅŸlem mevcut veritabanÄ±nÄ± silecek. Devam etmek istiyor musunuz? (y/N): ")
    if response.lower() not in ['y', 'yes', 'evet']:
        print("âŒ Ä°ÅŸlem iptal edildi.")
        sys.exit(0)
    
    # VeritabanÄ±nÄ± temizle
    clear_database()
    
    # KoleksiyonlarÄ± yeniden oluÅŸtur
    word_duration = rebuild_word_vectors()
    sentence_duration = rebuild_sentence_vectors()
    
    # DoÄŸrulama
    if verify_database():
        print("âœ… VeritabanÄ± doÄŸrulamasÄ± baÅŸarÄ±lÄ±")
    else:
        print("âŒ VeritabanÄ± doÄŸrulamasÄ± baÅŸarÄ±sÄ±z")
        sys.exit(1)
    
    # Ã–zet
    total_duration = time.time() - total_start_time
    
    print(f"\nğŸ† Ä°ÅLEM TAMAMLANDI!")
    print("=" * 30)
    print(f"â±ï¸  Kelime vektÃ¶rleri: {word_duration:.2f} saniye")
    print(f"â±ï¸  CÃ¼mle vektÃ¶rleri: {sentence_duration:.2f} saniye")
    print(f"â±ï¸  Toplam sÃ¼re: {total_duration:.2f} saniye")
    
    print(f"\nğŸ’¡ Ã–NERÄ°LER:")
    print(f"   â€¢ ArtÄ±k 'python app.py' ile uygulamanÄ±zÄ± baÅŸlatabilirsiniz")
    print(f"   â€¢ Performans testleri iÃ§in: 'python batch_performance_test.py'")
    print(f"   â€¢ VeritabanÄ± boyutu: {get_directory_size('db'):.1f} MB")

def get_directory_size(path):
    """Dizin boyutunu MB cinsinden hesapla"""
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for filename in filenames:
            filepath = os.path.join(dirpath, filename)
            total_size += os.path.getsize(filepath)
    return total_size / (1024 * 1024)  # MB

if __name__ == "__main__":
    main() 